{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Dirty Data with Pandas & Python\n",
    "http://www.developintelligence.com/blog/2017/08/data-cleaning-pandas-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this example, we work with a 5,000 movies scraped from IMDB file. This file has dirty data\n",
    "examplefile_path = \"../files/movie_metadata.csv\"\n",
    "cleanexamplefile_path = \"../files/out_movie_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the example CSV\n",
    "data = pd.read_csv(examplefile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check out the basic structure of the data we just read in, you can use the head() command to print out the first five rows.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the some basic stats for the ‘imdb_score’ column\n",
    "data.imdb_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a column: \n",
    "data[\"movie_title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the first 10 rows of a column:\n",
    "data[\"duration\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select multiple columns: \n",
    "data[[\"budget\",\"gross\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select all movies over two hours long: \n",
    "data[data[\"duration\"] > 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with missing data\n",
    "There are a couple of ways to deal with missing data:\n",
    " - Add in a default value for the missing data\n",
    " - Get rid of (delete) the rows that have missing data\n",
    " - Get rid of (delete) the columns that have a high incidence of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add default values\n",
    "\n",
    "#This replaces the NaN entries in the ‘country’ column with the empty string,\n",
    "data.country = data.country.fillna(\"\")\n",
    "#data.country = data.country.fillna(\"None Given\")  #Replaces NaN entries with \"None Given\" string\n",
    "\n",
    "#This replaces the NaN entries in the 'duration' column with mean duration of the rest of movies\n",
    "data.duration = data.duration.fillna(data.duration.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Remove incomplete rows\n",
    "\n",
    "#Dropping all rows with any NA values is easy:\n",
    "data.dropna()\n",
    "\n",
    "#Of course, we can also drop rows that have all NA values:\n",
    "data.dropna(how='all')\n",
    "\n",
    "#We can also put a limitation on how many non-null values need to be in a row in order to keep it\n",
    "data.dropna(thresh=5)\n",
    "\n",
    "#We don’t want to include any movie that doesn’t have information on when the movie came out:\n",
    "data.dropna(subset=['title_year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deal with error-prone columns\n",
    "#We can apply the same kind of criteria to our columns. \n",
    "#We just need to use the parameter axis=1 in our code. That means to operate on columns, not rows.\n",
    "\n",
    "#Drop the columns with that are all NA values:\n",
    "data.dropna(axis=1, how='all')\n",
    "\n",
    "#Drop all columns with any NA values:\n",
    "data.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data types\n",
    "Sometimes, especially when you’re reading in a CSV with a bunch of numbers, some of the numbers will read in as strings instead of numeric values, or vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data types: While you read the csv, you normalize the duration column datatype to int\n",
    "data = pd.read_csv(examplefile_path, dtype={'duration': float})\n",
    "\n",
    "#we want the release year to be a string and not a number\n",
    "data = pd.read_csv(examplefile_path, dtype={'title_year': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change casing\n",
    "People make typos, leave their caps lock on (or off), and add extra spaces where they shouldn’t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie titles to uppercase:\n",
    "data['movie_title'].str.upper()\n",
    "\n",
    "#get rid of trailing whitespace:\n",
    "data['movie_title'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename columns\n",
    "Computer-generated column names can be hard to read and understand while working, so if you want to rename a column to something more user-friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'title_year':'release_date', 'movie_facebook_likes':'facebook_likes'})\n",
    "\n",
    "#you’ll need to save the DataFrame by assigning it to a variable.\n",
    "data = data.rename(columns = {'title_year':'release_date', 'movie_facebook_likes':'facebook_likes'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your results\n",
    "When you’re done cleaning your data, you may want to export it back into CSV format for further processing in another program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(cleanexamplefile_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More resources\n",
    "Of course, this is only the tip of the iceberg. With variations in user environments, languages, and user input, there are many ways that a potential dataset may be dirty or corrupted. At this point you should have learned some of the most common ways to clean your dataset with Pandas and Python.\n",
    "\n",
    "For more resources on Pandas and data cleaning, see these additional resources:\n",
    "\n",
    "- Pandas documentation: https://pandas.pydata.org/pandas-docs/stable/\n",
    "- Messy Data Tutorial: http://nbviewer.jupyter.org/github/jvns/pandas-cookbook/blob/v0.1/cookbook/Chapter%207%20-%20Cleaning%20up%20messy%20data.ipynb\n",
    "- Kaggle Datasets: https://www.kaggle.com/datasets\n",
    "- Python for Data Analysis (“The Pandas Book”): http://shop.oreilly.com/product/0636920023784.do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
